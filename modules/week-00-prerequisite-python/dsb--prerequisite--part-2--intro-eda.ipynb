{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d3da14b-a002-43b1-8fd4-f67efcb71d7e",
   "metadata": {},
   "source": [
    "# Data Science for Business\n",
    "**Faculty of Economics and Business**  \n",
    "**Accounting Department**  \n",
    "**Master of Accounting Program**  \n",
    "**Universitas Indonesia**\n",
    "\n",
    "\n",
    "**Course:** Data Science for Business (ECEM801201)  \n",
    "**Semester:** Odd Semester 2025/2026   \n",
    "**Part**: [2] Introduction to Exploratory Data Analysis   \n",
    "**Content**: Prerequisite Material\n",
    "\n",
    "---\n",
    "\n",
    "## Class Information\n",
    "\n",
    "| Lecturer| Name | Contact |\n",
    "|------------|-------------|---------|\n",
    "| Lecturer | Yudhistira Dharma Putra, S.E., M.Sc. | y.dharma@ui.ac.id |\n",
    "| Assistant Lecturer | Fiqry Revadiansyah | fiqryrevadiansyah@gmail.com |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fedab4b-2932-4cb7-8948-9b979410eade",
   "metadata": {},
   "source": [
    "## âœ… Learning Objectives\n",
    "\n",
    "By the end of this notebook, you should be able to:\n",
    "\n",
    "- [ ] Load and explore datasets using **Pandas**  \n",
    "- [ ] Analyze **categorical and numerical columns** with grouping and aggregation  \n",
    "- [ ] Detect and handle **missing values** in business datasets  \n",
    "- [ ] Create **basic visualizations** (histogram, bar chart, pie chart, line chart) for business insights  \n",
    "- [ ] Interpret patterns and trends from data to support **accounting and financial decision-making**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1801ac02-9572-455d-a507-621a23058e24",
   "metadata": {},
   "source": [
    "## Part 2: Working with Data Using Pandas\n",
    "\n",
    "Now that you understand Python basics, weâ€™ll work with real business data using **Pandas**, Pythonâ€™s most popular data analysis library.  \n",
    "Think of Pandas as **Excel on steroids**: it reads spreadsheets and CSVs, lets you filter/sort/group data, computes metrics, and integrates seamlessly with chartsâ€”while being reproducible and scalable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2290b17b-be5d-4f33-a201-72056bc2ee08",
   "metadata": {},
   "source": [
    "### 2.1 Loading and Exploring Our Dataset\n",
    "\n",
    "**What youâ€™ll learn in this section**\n",
    "- Load a dataset from disk into a Pandas DataFrame\n",
    "- Do a quick health check: shape, columns, data types, nulls, and basic stats\n",
    "- Get a â€œfirst feelâ€ of the data to guide later cleaning and analysis\n",
    "\n",
    "**Concepts to know before running the code**\n",
    "- DataFrame: a table-like object with labeled rows and columns\n",
    "- Series: a single column of a DataFrame\n",
    "- Schema: the set of column names and their data types (numeric, text, dates, etc.)\n",
    "\n",
    "**What the code will do**\n",
    "- Import core libraries for analysis and plotting (pandas, numpy, matplotlib, seaborn)\n",
    "- Load the CSV file into a DataFrame (pay attention to the file path)\n",
    "- Print:\n",
    "  - A success message and the shape (rows Ã— columns)\n",
    "  - The first few rows for a visual sanity check\n",
    "  - Column information including data types and non-null counts\n",
    "  - Descriptive statistics for numeric columns (count, mean, std, min, quartiles, max)\n",
    "\n",
    "**Why each step matters**\n",
    "- Head (first rows): quickly spot obvious issues like misaligned columns or strange values\n",
    "- Shape: confirms you loaded the full dataset (row/column counts as expected)\n",
    "- Info: reveals data types, missing values, and memory footprint\n",
    "- Describe: highlights distributions, outliers, and suspicious zeros or negatives\n",
    "\n",
    "**Common pitfalls and how to avoid them**\n",
    "- File path errors: ensure the relative path points to the correct folder\n",
    "- Wrong delimiter or encoding: if data looks â€œsquashedâ€ into one column, check CSV delimiter and encoding\n",
    "- Mis-typed columns (numbers read as text): youâ€™ll fix this in the cleaning step (casting types)\n",
    "- Large datasets: consider loading a sample first or using chunks for memory efficiency\n",
    "\n",
    "**Quality checks to keep in mind**\n",
    "- Do column names match your expectations?\n",
    "- Are date columns recognized as dates (or as text)?\n",
    "- Are there missing values in critical fields (IDs, amounts, dates)?\n",
    "- Do numeric columns have realistic ranges for your business context?\n",
    "\n",
    "**What â€œgoodâ€ looks like after this step**\n",
    "- You can articulate what each column represents\n",
    "- You know the datasetâ€™s size and basic structure\n",
    "- Youâ€™ve identified initial issues to clean in the next steps (missing values, types, outliers)\n",
    "\n",
    "**Next steps preview**\n",
    "- 2.2: Data cleaning (handling missing values, fixing data types, de-duplicating)\n",
    "- 2.3: Feature engineering (new columns, buckets, business rules)\n",
    "- 2.4: Aggregation and business metrics (groupby, pivot)\n",
    "- 2.5: Visualization for insights (trends, distributions, comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da26f20-9e61-4bdd-9457-9665068216e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../week-02-business-problems-data-solutions/data/w2--dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149bd2f2-5907-4906-94ef-a0e2d1b0f2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d238a426-3c52-43be-9523-d0651d73d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First look at the data\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a313bed8-7c14-46da-86c6-89d29fb9b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Column information:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a16a2ee-213d-441f-84d3-5db3c36a0875",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Basic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d4ba34-5526-419b-9a6f-d6cd76d2fd62",
   "metadata": {},
   "source": [
    "### 2.2 Data Exploration and Analysis\n",
    "\n",
    "In Pandas, exploratory data analysis (EDA) is how we â€œget to knowâ€ the dataset before modeling or reporting.\n",
    "You can think of it as the first audit pass: verify columns, scan values, and surface data issues early.\n",
    "\n",
    "ðŸ“Œ Analogy for Accounting:\n",
    "Just as an auditor reviews a trial balance to spot anomalies (missing entries, wrong types, out-of-range values), EDA checks each columnâ€™s content, completeness, and basic statistics to ensure downstream calculations are trustworthy.\n",
    "\n",
    "Key Steps Weâ€™ll Perform\n",
    "1) Categorical scan  \n",
    "   - Identify text/object columns (e.g., customer, region, currency).  \n",
    "   - Count unique values and preview a few examples to spot typos or unexpected categories.\n",
    "\n",
    "2) Missing-value audit  \n",
    "   - Tally nulls per column to gauge data completeness.  \n",
    "   - Decide what is â€œcriticalâ€ (e.g., posting_date, total_open_amount) and must not be missing.\n",
    "\n",
    "3) Business status snapshot (if column exists)  \n",
    "   - Summarize operational flags (e.g., isOpen) to see open vs closed entities and their proportions.\n",
    "\n",
    "4) Spending overview  \n",
    "   - Auto-detect columns containing â€œspendâ€ or â€œamountâ€.  \n",
    "   - Compute average, median, min, and max to understand ranges and outliers.\n",
    "\n",
    "5) Basic cleaning  \n",
    "   - Drop rows missing critical fields (e.g., posting_date, total_open_amount).  \n",
    "   - Fill missing categorical with â€œUnknownâ€.  \n",
    "   - Fill missing numeric with the median (more robust than mean for skewed data).  \n",
    "   - Recheck missing values after cleaning.\n",
    "\n",
    "6) Grouping and aggregation  \n",
    "   - By business year: total open amount trend across years.  \n",
    "   - By customer: average invoice size per customer.  \n",
    "   - By currency: count, mean, and sum to understand currency exposure.\n",
    "\n",
    "Examples of What Youâ€™ll Read From the Output\n",
    "- â€œWe have N customers and M unique currencies; top categories look sensible.â€  \n",
    "- â€œ5% of rows miss posting_date; weâ€™ll drop those to avoid timing distortions.â€  \n",
    "- â€œMedian transaction is far below the mean, suggesting a few very large invoices.â€  \n",
    "- â€œYear-over-year totals show growth (or contraction); currency XYZ dominates exposure.â€\n",
    "\n",
    "Financial/Business Interpretation\n",
    "- Data completeness drives reliability of KPIs (revenue, AR aging, margins).  \n",
    "- Distribution checks prevent a few extreme values from misleading averages.  \n",
    "- Grouped views (year, customer, currency) align with executive reporting and risk monitoring.  \n",
    "- Clear handling rules (drop vs fill) make analyses reproducible and auditable.\n",
    "\n",
    "âœ… Why do EDA first?\n",
    "- Quality control: catch problems before they contaminate metrics.  \n",
    "- Faster iteration: know which columns are usable and how.  \n",
    "- Credible insights: summaries reflect real business behavior, not data artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ebd8f5-abbc-41c9-9969-0286ede8a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ·ï¸ Explore categorical columns\n",
    "# Step 1: Identify all categorical (object) columns in the dataset\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(\"Unique values in categorical columns:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Step 2: Loop through each categorical column\n",
    "# Display how many unique values and list them\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")\n",
    "    print(f\"Values: {list(df[col].unique())[:5]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fae1e0-7aa8-42d0-a587-207dfa037b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ” Check for missing values\n",
    "# This helps us understand data completeness\n",
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a93f880-0a75-4e03-b01d-536249508d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Business status analysis (if column 'isOpen' exists)\n",
    "# This checks how many businesses are still operating vs closed\n",
    "if 'isOpen' in df.columns:\n",
    "    business_status = df['isOpen'].value_counts()\n",
    "    print(\"Business Status Distribution:\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    for status, count in business_status.items():\n",
    "        percentage = (count / len(df)) * 100\n",
    "        label = \"Open\" if status == 1 else \"Closed\"\n",
    "        print(f\"{label}: {count} businesses ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88417e57-a7b5-42cc-be96-792d964ff2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ’° Spending analysis\n",
    "# Automatically detect columns related to spending or amount\n",
    "spending_cols = [col for col in df.columns if 'spend' in col.lower() or 'amount' in col.lower()]\n",
    "\n",
    "if spending_cols:\n",
    "    print(\"Spending Analysis (first 3 columns):\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for col in spending_cols[:3]:  # Limit to first 3 spending columns\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Average: ${df[col].mean():,.2f}\")\n",
    "        print(f\"  Median: ${df[col].median():,.2f}\")\n",
    "        print(f\"  Min: ${df[col].min():,.2f}\")\n",
    "        print(f\"  Max: ${df[col].max():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a4044-ef14-40c7-b888-b788eb1f09de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§¹ Handling Missing Values\n",
    "\n",
    "# 1. Check again which columns have missing values\n",
    "print(\"Missing values before handling:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 2. Example: Drop rows where critical columns (like 'posting_date' or 'total_open_amount') are missing\n",
    "df_cleaned = df.dropna(subset=['posting_date', 'total_open_amount'])\n",
    "\n",
    "# 3. Example: Fill missing values for categorical columns with \"Unknown\"\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "df_cleaned[categorical_cols] = df_cleaned[categorical_cols].fillna(\"Unknown\")\n",
    "\n",
    "# 4. Example: Fill missing numeric columns with median (safer than mean if data is skewed)\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "for col in numeric_cols:\n",
    "    df_cleaned[col] = df_cleaned[col].fillna(df_cleaned[col].median())\n",
    "\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(df_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4945f588-2c56-465e-923f-c2a7672f2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Grouping and Aggregation with Pandas\n",
    "\n",
    "# Example 1: Total open amount per business year\n",
    "amount_by_year = df_cleaned.groupby('buisness_year')['total_open_amount'].sum().reset_index()\n",
    "print(amount_by_year.head())\n",
    "\n",
    "# Example 2: Average open amount per customer\n",
    "amount_by_customer = df_cleaned.groupby('cust_number')['total_open_amount'].mean().reset_index()\n",
    "print(amount_by_customer.head())\n",
    "\n",
    "# Example 3: Total open amount by currency\n",
    "amount_by_currency = df_cleaned.groupby('invoice_currency')['total_open_amount'].agg(['count', 'mean', 'sum']).reset_index()\n",
    "print(amount_by_currency.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc084150-a000-4756-87b3-234a933acdd6",
   "metadata": {},
   "source": [
    "### 2.3 Data Visualization  \n",
    "\n",
    "In Pandas and Python, data visualization turns raw numbers into **visual stories**.  \n",
    "You can think of it as transforming a financial report full of tables into dashboards or charts that reveal trends instantly.\n",
    "\n",
    "ðŸ“Œ Analogy for Accounting:  \n",
    "Just as management prefers a dashboard with graphs of revenue trends, cost breakdowns, or customer growth instead of raw spreadsheets, visualization in Python helps us see patterns, outliers, and relationships that tables alone canâ€™t show.\n",
    "\n",
    "---\n",
    "\n",
    "Common Types of Business Visuals\n",
    "1) Bar charts â†’ compare revenue or expenses across categories (e.g., top 10 customers by sales).  \n",
    "2) Line charts â†’ track trends over time (e.g., monthly revenue growth, year-over-year performance).  \n",
    "3) Histograms â†’ examine distributions (e.g., invoice amounts, payment delays).  \n",
    "4) Boxplots â†’ detect outliers (e.g., unusually high spending transactions).  \n",
    "5) Heatmaps â†’ visualize correlations (e.g., between sales, discounts, and profitability).  \n",
    "\n",
    "---\n",
    "\n",
    "Basic Tools Weâ€™ll Use\n",
    "- **Matplotlib**: the foundational plotting library in Python.  \n",
    "- **Seaborn**: built on Matplotlib, provides cleaner, business-ready charts with less code.  \n",
    "- **Pandas `.plot()`**: quick access for simple charts directly from DataFrames.  \n",
    "\n",
    "---\n",
    "\n",
    "Examples of Visual Business Insights\n",
    "- Revenue by year â†’ growth vs decline.  \n",
    "- Average invoice size by customer â†’ identify high-value clients.  \n",
    "- Expense composition by category â†’ which costs dominate the budget.  \n",
    "- Payment delay distribution â†’ spot operational bottlenecks.  \n",
    "\n",
    "---\n",
    "\n",
    "âœ… Why use visualization?\n",
    "- Makes patterns visible that summary statistics might hide.  \n",
    "- Helps non-technical stakeholders (executives, managers) grasp insights quickly.  \n",
    "- Provides evidence for decisions by showing trends, risks, and anomalies in context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4f5ee8-df7c-49a0-aceb-48ef3f374b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Visualization Setup\n",
    "# Purpose: Prepare column types and a clean plotting style before building the dashboard\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Identify column types (recompute to be safe if df changed earlier)\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Optional: consistent plot styling\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178ac0ba-58bf-4f26-82ee-2396a2d2c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Visualization 1: Business Status Distribution\n",
    "# If the dataset has a column 'isOpen', show how many businesses are open vs closed.\n",
    "\n",
    "if 'isOpen' in df.columns:\n",
    "    status_counts = df['isOpen'].value_counts(dropna=False)\n",
    "    labels = ['Closed' if x == 0 else 'Open' for x in status_counts.index]\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.pie(status_counts.values, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Business Status Distribution')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Column 'isOpen' not found in dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb1617-36c6-4ff2-a1bf-1638f31e3130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Visualization 2: Histogram visualization\n",
    "# ðŸ“Š Histogram for a specific numeric column\n",
    "\n",
    "col = \"total_open_amount\"   # choose column manually\n",
    "\n",
    "if col in df.columns:\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.hist(df[col].dropna(), bins=20, color='skyblue', edgecolor='black')\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Column {col} not found in dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76231178-16ae-4bc1-a33d-b4b5a73a4d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Visualization 3: Correlation Heatmap\n",
    "# Show correlations between the first 5 numeric columns (to see relationships).\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "if len(numeric_cols) >= 2:\n",
    "    cols_for_corr = numeric_cols[:5]   # Limit to 5 columns for clarity\n",
    "    corr_matrix = df[cols_for_corr].corr(numeric_only=True)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Correlation Matrix (Top 5 numeric columns)')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough numeric columns for correlation analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b21c108-0879-4fe5-bf3d-5c73db5d5448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Visualization 4: Category Analysis\n",
    "# Show the top 10 categories for the first categorical column.\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    col = categorical_cols[0]\n",
    "    top_categories = df[col].value_counts(dropna=False).head(10)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    top_categories.plot(kind='bar', color='orange', edgecolor='black')\n",
    "    plt.title(f'Top 10 Categories in {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No categorical columns found in dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ef5e2-d2bb-4f9f-adbd-3750b4c1b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Time Series Visualization: Total Open Amount by Posting Date\n",
    "\n",
    "# Step 1: Convert posting_date to datetime\n",
    "df['posting_date'] = pd.to_datetime(df['posting_date'], errors='coerce')\n",
    "\n",
    "# Step 2: Group by posting_date and sum the total_open_amount\n",
    "time_series = df.groupby('posting_date')['total_open_amount'].sum().reset_index()\n",
    "\n",
    "# Step 3: Plot the time series\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series['posting_date'], time_series['total_open_amount'], marker='o', linestyle='-')\n",
    "plt.title('Total Open Amount Over Time')\n",
    "plt.xlabel('Posting Date')\n",
    "plt.ylabel('Total Open Amount')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47264874-d54e-4cab-8e74-efd28f7da993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“ˆ  Visualizations for Aggregations\n",
    "\n",
    "# Total amount by year\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(amount_by_year['buisness_year'], amount_by_year['total_open_amount'], color='teal')\n",
    "plt.title('Total Open Amount per Year')\n",
    "plt.xlabel('Business Year')\n",
    "plt.ylabel('Total Amount')\n",
    "plt.show()\n",
    "\n",
    "# Top 10 customers by total amount\n",
    "top_customers = df_cleaned.groupby('cust_number')['total_open_amount'].sum().nlargest(10).reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(top_customers['cust_number'].astype(str), top_customers['total_open_amount'], color='orange')\n",
    "plt.title('Top 10 Customers by Total Open Amount')\n",
    "plt.xlabel('Customer Number')\n",
    "plt.ylabel('Total Amount')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fbb78d-f32d-4b2e-baea-2f96bea36c74",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Try with your own\n",
    "\n",
    "---\n",
    "\n",
    "## Soal 1 â€“ Analisis Tren Waktu  \n",
    "Dataset memiliki kolom `posting_date` dan `total_open_amount`.  \n",
    "\n",
    "**Tugas:**  \n",
    "- Konversikan `posting_date` menjadi tipe datetime.  \n",
    "- Hitung total `total_open_amount` **per bulan**.  \n",
    "- Buat **line chart** untuk menunjukkan tren bulanan tersebut.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b35c571-cc4c-4856-a95e-5574a71a9e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jawab disini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996c3c43-8cf7-47bb-8114-7defb57eff89",
   "metadata": {},
   "source": [
    "## Soal 2 â€“ Analisis Pelanggan  \n",
    "Kolom `cust_number` mewakili pelanggan.  \n",
    "\n",
    "**Tugas:**  \n",
    "- Hitung total `total_open_amount` untuk setiap pelanggan.  \n",
    "- Tampilkan **5 pelanggan dengan transaksi terbesar**.  \n",
    "- Buat **bar chart** untuk 5 pelanggan tersebut.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064170ae-4c2e-4224-9723-80e6794acd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jawab disini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7b7d24-0e73-4ee6-af98-f225e7da029b",
   "metadata": {},
   "source": [
    "## Soal 3 â€“ Analisis Mata Uang  \n",
    "Kolom `invoice_currency` menyimpan jenis mata uang.  \n",
    "\n",
    "**Tugas:**  \n",
    "- Hitung jumlah transaksi untuk setiap jenis mata uang.  \n",
    "- Hitung rata-rata `total_open_amount` per mata uang.  \n",
    "- Visualisasikan hasilnya dengan **bar chart** (mata uang vs rata-rata transaksi).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85b336f-73ac-4e48-8af5-e27dd2009048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jawab disini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b31710-60c4-4fe4-be4d-4b17d40baa57",
   "metadata": {},
   "source": [
    "## Soal 4 â€“ Analisis Status Bisnis  \n",
    "Kolom `isOpen` menandakan status (0 = closed, 1 = open).  \n",
    "\n",
    "**Tugas:**  \n",
    "- Hitung proporsi bisnis yang **masih open** vs **sudah closed**.  \n",
    "- Buat **pie chart** untuk distribusi status ini.  \n",
    "- Bandingkan rata-rata `total_open_amount` antara bisnis open dan closed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a55257c-f0ab-4147-8950-5a852d25cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jawab disini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3148885c-6900-40d5-83cd-bd77fa5105b5",
   "metadata": {},
   "source": [
    "## Soal 5 â€“ Korelasi & Insight Numerik  \n",
    "Dataset memiliki beberapa kolom numerik (`total_open_amount`, `doc_id`, `invoice_id`, dll.).  \n",
    "\n",
    "**Tugas:**  \n",
    "- Pilih 5 kolom numerik pertama.  \n",
    "- Buat **correlation matrix** dan tampilkan dengan **heatmap**.  \n",
    "- Tulis insight singkat: kolom mana yang punya korelasi paling tinggi? kolom mana yang paling lemah?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d6272d-aa93-4838-8298-18d7550abbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jawab disini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2901a84d-503b-4c12-b42b-e21375886ef2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ“Œ Conclusion & Next Steps\n",
    "\n",
    "In this notebook, we have explored the **fundamentals of Pandas and data visualization** with applications in business and accounting.  \n",
    "Key concepts covered include:  \n",
    "- Loading and exploring datasets with **Pandas** (`read_csv`, `head`, `info`, `describe`)  \n",
    "- Handling **categorical and numeric data**  \n",
    "- Detecting and analyzing **missing values**  \n",
    "- Using **groupby and aggregations** for business insights  \n",
    "- Creating **visualizations** with Matplotlib and Seaborn (histograms, bar charts, pie charts, heatmaps, time series)  \n",
    "\n",
    "These skills allow us to **transform raw financial and accounting data into meaningful insights** that support better business decision-making.  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”œ Whatâ€™s Next?\n",
    "In the following sessions, we will build upon these capabilities by:\n",
    "- Preparing datasets for **machine learning models** in finance and accounting  \n",
    "\n",
    "---\n",
    "\n",
    "**Thank you for completing Part 2: Introduction to Exploratory Data Analysis .**  \n",
    "Letâ€™s continue the journey into more advanced analytics and machine learning for business! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
