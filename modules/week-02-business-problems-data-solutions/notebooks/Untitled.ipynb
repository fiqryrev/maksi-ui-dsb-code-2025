{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2194333f-a8bd-4356-8b9c-2f76d83be2b3",
   "metadata": {},
   "source": [
    "# Data Science for Business\n",
    "**Faculty of Economics and Business**  \n",
    "**Accounting Department**  \n",
    "**Master of Accounting Program**  \n",
    "**Universitas Indonesia**\n",
    "\n",
    "\n",
    "**Course:** Data Science for Business (ECEM801201)  \n",
    "**Semester:** Odd Semester 2025/2026   \n",
    "**Part**: Business Problem with Data Solutions   \n",
    "**Content**: Supervised & Unsupervised Machine Learning\n",
    "\n",
    "---\n",
    "\n",
    "## Class Information\n",
    "\n",
    "| Lecturer| Name | Contact | Linkedin | \n",
    "|------------|-------------|---------|---------|\n",
    "| Lecturer | Yudhistira Dharma Putra, S.E., M.Sc. | y.dharma@ui.ac.id | https://id.linkedin.com/in/yudhistira-dharma-putra-91367256 |\n",
    "| Assistant Lecturer | Fiqry Revadiansyah | fiqryrevadiansyah@gmail.com | https://www.linkedin.com/in/fiqryrevadiansyah/ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86a4402-3ac7-4f42-b00b-90c6289172ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c377eed-34f8-485f-9816-b9b5c68a5aae",
   "metadata": {},
   "source": [
    "# Part 3: Supervised Learning: Classification\n",
    "\n",
    "In supervised learning, we teach a model using examples that already have the correct answer (the label). After learning patterns from these labeled examples, the model predicts the label for new, unseen data.\n",
    "\n",
    "📌 Accounting analogy  \n",
    "An auditor studies past transactions labeled fraud or legitimate. After enough examples, the auditor can flag risky transactions in a fresh ledger. That is classification.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150565c1-9cc0-4b7d-9bf1-f17690bc2447",
   "metadata": {},
   "source": [
    "## 3.1 Problem framing\n",
    "\n",
    "- **Goal**: predict a **category** for each record  \n",
    "  Examples: is a business still open (1) or closed (0), is a transaction fraud or not, will a customer default or not.\n",
    "- **Input** (**X**, features): columns like revenue growth, cash ratio, industry, account age.\n",
    "- **Output** (**y**, label): the thing to predict, such as `isOpen` or `isFraud`.\n",
    "- **Train vs test split**: learn patterns on training data, judge generalization on test data.\n",
    "\n",
    "Key ideas  \n",
    "- **Generalization**: doing well on unseen data.  \n",
    "- **Bias vs variance**: simple models may underfit (high bias). Complex models may overfit (high variance).  \n",
    "- **Data leakage**: do not use any future or target-derived information during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "047aef6f-a688-41a9-9b2d-6e3baf93b04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (50000, 19)\n",
      "Number of numeric features (X): 10\n",
      "First 5 feature names: ['buisness_year', 'doc_id', 'document_create_date', 'document_create_date.1', 'due_in_date']\n",
      "\n",
      "Target distribution (y):\n",
      "isOpen\n",
      "class 0    80.0%\n",
      "class 1    20.0%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Problem Framing — one simple cell\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TARGET_COL = \"isOpen\"\n",
    "df = pd.read_csv('../data/w2--dataset.csv')\n",
    "\n",
    "# 1) Make sure target exists (create a simple demo target if missing)\n",
    "if TARGET_COL not in df.columns:\n",
    "    print(f\"[Info] '{TARGET_COL}' not found. Creating a demo target for teaching.\")\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if num_cols:\n",
    "        key = num_cols[0]\n",
    "        thresh = df[key].median()\n",
    "        df[TARGET_COL] = (df[key] > thresh).astype(int)\n",
    "    else:\n",
    "        np.random.seed(42)\n",
    "        df[TARGET_COL] = np.random.choice([0, 1], size=len(df))\n",
    "\n",
    "# 2) Define X (features) and y (label) — use numeric features only for now\n",
    "feature_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if TARGET_COL in feature_cols:\n",
    "    feature_cols.remove(TARGET_COL)\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[TARGET_COL].copy()\n",
    "\n",
    "# 3) Quick summary\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Number of numeric features (X):\", len(feature_cols))\n",
    "print(\"First 5 feature names:\", feature_cols[:5])\n",
    "print(\"\\nTarget distribution (y):\")\n",
    "print(y.value_counts(normalize=True).rename(lambda k: f\"class {k}\").mul(100).round(1).astype(str) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7dbd8a-340a-4932-84a3-4925b21e9d98",
   "metadata": {},
   "source": [
    "## 3.2 Data preparation checklist\n",
    "\n",
    "1) **Target definition**  \n",
    "   - Confirm the label is aligned with the business question and time horizon.  \n",
    "   - Example: `isOpen` refers to next quarter status, not current status.\n",
    "\n",
    "2) **Train and test split**  \n",
    "   - Use stratification for imbalanced classes.  \n",
    "   - Keep the test set cold (no peeking).\n",
    "\n",
    "3) **Feature engineering**  \n",
    "   - Numeric features: raw values, ratios, growth, log transforms.  \n",
    "   - Categorical features: industry, region, risk tier.  \n",
    "   - Dates: convert to age, month, seasonality indicators.  \n",
    "   - Aggregations: customer-level averages, rolling statistics.\n",
    "\n",
    "4) **Missing values**  \n",
    "   - Impute with mean or median for numeric, most frequent for categorical.  \n",
    "   - Add missingness indicators when it carries signal.\n",
    "\n",
    "5) **Scaling**  \n",
    "   - Needed for distance or margin-based models (k-NN, SVM, logistic regression, neural nets).  \n",
    "   - Not required for trees and tree ensembles.\n",
    "\n",
    "6) **Encoding categoricals**  \n",
    "   - One-hot encoding for low or medium cardinality.  \n",
    "   - Target or CatBoost encoding for high-cardinality categoricals.  \n",
    "   - Some libraries (CatBoost) handle categoricals natively.\n",
    "\n",
    "7) **Pipelines**  \n",
    "   - Wrap preprocessing and models in a single pipeline to avoid leakage and keep training consistent.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93c8c0cd-68a5-48df-82ef-f94aec38bebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.12/site-packages/sklearn/impute/_base.py:637: UserWarning: Skipping features without any observed values: ['area_business']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.12/site-packages/sklearn/impute/_base.py:637: UserWarning: Skipping features without any observed values: ['area_business']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prep complete.\n",
      "Numeric features: 10 | Categorical features: 8\n",
      "X_train_ready shape: (40000, 6058) | X_test_ready shape: (10000, 6058)\n",
      "y_train distribution: {0: 0.8, 1: 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.12/site-packages/sklearn/impute/_base.py:637: UserWarning: Skipping features without any observed values: ['area_business']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Data Preparation — one simple cell (checklist → code)\n",
    "#\n",
    "# This cell prepares data for ML with a clean, reusable sklearn Pipeline:\n",
    "# - Defines target and splits (if not already split)\n",
    "# - Engineers simple date features (year, month, quarter, age_days)\n",
    "# - Imputes missing values (numeric=median+indicator, categorical=most_frequent)\n",
    "# - One-hot encodes categoricals\n",
    "# - Scales numeric features (good for LR/SVM/NN; trees don’t need it but harmless)\n",
    "# - Wraps everything in a Pipeline/ColumnTransformer to avoid leakage\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "TARGET_COL = \"isOpen\"\n",
    "\n",
    "# --- 1) Split data (stratified so class balance is preserved) ---\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- 2) Identify numeric vs categorical features ---\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# --- 3) Preprocessing pipelines ---\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "    (\"scaler\", StandardScaler())  # scaling useful for LR/SVM/NN\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))  # <- FIX\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# --- 4) Fit on training, transform both train & test ---\n",
    "preprocess.fit(X_train)\n",
    "\n",
    "X_train_ready = preprocess.transform(X_train)\n",
    "X_test_ready  = preprocess.transform(X_test)\n",
    "\n",
    "print(\"Prep complete.\")\n",
    "print(\"Numeric features:\", len(numeric_features), \"| Categorical features:\", len(categorical_features))\n",
    "print(\"X_train_ready shape:\", X_train_ready.shape, \"| X_test_ready shape:\", X_test_ready.shape)\n",
    "print(\"y_train distribution:\", y_train.value_counts(normalize=True).round(2).to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b72e456-5a57-42e5-8953-b97de1d04e11",
   "metadata": {},
   "source": [
    "## 3.3 Evaluation and business alignment\n",
    "\n",
    "### Common metrics\n",
    "- **Accuracy**: percent correct. Simple baseline, can mislead under imbalance.  \n",
    "- **Balanced accuracy**: average of recall across classes. Better when classes are imbalanced.  \n",
    "- **Precision (for positive class)**: out of predicted positives, how many are truly positive.  \n",
    "- **Recall (for positive class)**: out of all true positives, how many did we catch.  \n",
    "- **F1 score**: harmonic mean of precision and recall.  \n",
    "- **ROC-AUC**: probability the model ranks a random positive above a random negative.  \n",
    "- **PR-AUC**: precision-recall area, more informative under heavy imbalance.  \n",
    "- **Log loss**: measures probability quality. Useful when you will use calibrated probabilities.\n",
    "\n",
    "### Threshold tuning\n",
    "- Models output probabilities. You choose a decision threshold (often 0.5 by default).  \n",
    "- Optimize the threshold using business costs.  \n",
    "  - Example: fraud detection where missing a fraud is expensive. Choose a threshold that maximizes expected profit or minimizes expected cost.\n",
    "\n",
    "### Confusion matrix and costs\n",
    "- **TP**: correctly predicted positive  \n",
    "- **FP**: predicted positive but actually negative  \n",
    "- **FN**: predicted negative but actually positive  \n",
    "- **TN**: correctly predicted negative\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3398d38-f077-4e46-bb99-6dc14cbf6ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Evaluasi & Alignment Bisnis — DEMO SATU SEL (dummy data akuntansi/keuangan)\n",
    "#\n",
    "# Konteks: Deteksi \"Transaksi Fraud\" (positif = 1) vs \"Transaksi Non Fraud\" (negatif = 0)\n",
    "# Contoh nyata: penipuan kartu, klaim biaya fiktif, atau invoice yang berpotensi gagal bayar.\n",
    "# y_true  : label aktual dari tim audit/risk\n",
    "# y_score : probabilitas dari model bahwa transaksi berisiko (semakin besar = makin berisiko)\n",
    "# y_pred  : keputusan 0/1 berdasarkan ambang (threshold)\n",
    "#\n",
    "# Output:\n",
    "# - Confusion Matrix (TP/FP/FN/TN) + penjelasan istilah\n",
    "# - Accuracy, Precision, Recall, F1, Specificity, Balanced Accuracy\n",
    "# - ROC-AUC, PR-AUC, Log Loss\n",
    "# - Perbandingan threshold 0.5 vs 0.3\n",
    "# - Simulasi biaya: cost_fp (review manual transaksi aman yang salah ditandai berisiko)\n",
    "#                   cost_fn (kerugian jika transaksi berisiko lolos)\n",
    "#\n",
    "# Catatan: Satu sel saja. Nanti Anda bisa pecah per metrik sesuai kebutuhan.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, log_loss,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Dummy data akuntansi/keuangan\n",
    "# -----------------------------\n",
    "# 15 transaksi: 1 = berisiko (fraud/gagal bayar), 0 = aman\n",
    "# Contoh: transaksi #1, #3, #7, #11 berisiko (ground truth dari audit)\n",
    "y_true = np.array([\n",
    "    1, 0, 1, 0, 0,\n",
    "    0, 1, 0, 0, 0,\n",
    "    1, 0, 0, 0, 0\n",
    "])\n",
    "\n",
    "# Probabilitas model \"seberapa berisiko\" transaksi\n",
    "# Angka besar berarti model curiga transaksi berisiko\n",
    "y_score = np.array([\n",
    "    0.85, 0.40, 0.72, 0.10, 0.22,\n",
    "    0.55, 0.65, 0.18, 0.12, 0.33,\n",
    "    0.49, 0.31, 0.08, 0.27, 0.60\n",
    "])\n",
    "\n",
    "# Threshold default 0.5 (sering jadi standar awal)\n",
    "thr_default = 0.50\n",
    "y_pred = (y_score >= thr_default).astype(int)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Confusion matrix + istilah\n",
    "# -----------------------------\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "TN, FP, FN, TP = cm.ravel()  # baris aktual [0,1] x kolom pred [0,1]\n",
    "\n",
    "print(\"=== Konteks Bisnis (Deteksi Transaksi Fraud) ===\")\n",
    "print(\"- Positif (1)   : Transaksi Berisiko (fraud/gagal bayar)\")\n",
    "print(\"- Negatif (0)   : Transaksi Aman\")\n",
    "print(\"- TP (True +)   : Dianggap Fraud & kenyataannya Fraud → kerugian dihindari\")\n",
    "print(\"- FP (False +)  : Dianggap Fraud & kenyataannya tidak Fraud → biaya review manual/komplain nasabah\")\n",
    "print(\"- FN (False -)  : Dianggap tidak Fraud & kenyataannya Fraud → kerugian finansial\")\n",
    "print(\"- TN (True -)   : Dianggap tidak Fraud & kenyataannya tidak Fraud\\n\")\n",
    "\n",
    "print(f\"=== Confusion Matrix @ threshold {thr_default:.2f} ===\")\n",
    "print(\"[ [TN FP] ; [FN TP] ]\")\n",
    "print(cm)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Metrik klasifikasi dasar\n",
    "# -----------------------------\n",
    "accuracy  = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "recall    = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1        = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "# Specificity = TN / (TN + FP)\n",
    "specificity = TN / (TN + FP) if (TN + FP) > 0 else 0.0\n",
    "balanced_acc = (recall + specificity) / 2\n",
    "\n",
    "# Metrik berbasis probabilitas (threshold-independent)\n",
    "eps = 1e-7\n",
    "p = np.clip(y_score, eps, 1 - eps)\n",
    "roc_auc = roc_auc_score(y_true, y_score)\n",
    "pr_auc  = average_precision_score(y_true, y_score)\n",
    "ll      = log_loss(y_true, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37bd4f0a-c865-42eb-8f0e-38d284ef6e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Akurasi)    : 0.800\n",
      "  → Seberapa sering tebakan sistem benar secara keseluruhan (baik saat memblokir penipu maupun meloloskan pembeli jujur).\n",
      "  → Ibarat nilai rapor umum sistem.\n",
      "  → PERHATIAN: Akurasi bisa menipu jika jumlah transaksi asli jauh lebih banyak dari transaksi fraud. Sistem bisa dapat nilai 99% hanya dengan meloloskan semua transaksi, padahal semua penipunya ikut lolos.\n",
      "\n",
      "Precision (Presisi)     : 0.600\n",
      "  → Dari semua transaksi yang DIBLOKIR oleh sistem, berapa persen yang BENAR-BENAR penipuan?\n",
      "  → Mengukur KUALITAS pemblokiran. Jangan sampai sering salah blokir!\n",
      "  → Jika Precision TINGGI: Sistem sangat bisa diandalkan. Saat ia memblokir sesuatu, hampir pasti itu penipuan. Ini penting agar tidak membuat pelanggan jujur kecewa karena transaksinya ditolak.\n",
      "  → Jika Precision RENDAH: Sistem terlalu 'parno'. Banyak transaksi dari pembeli jujur yang ikut diblokir. Ini menyebabkan pengalaman belanja yang buruk dan banyak komplain pelanggan.\n",
      "\n",
      "Recall (Daya Jangkau)   : 0.750\n",
      "  → Dari semua transaksi penipuan yang SEBENARNYA terjadi, berapa persen yang berhasil DISARING/DIBLOKIR oleh sistem?\n",
      "  → Mengukur KEMAMPUAN sistem dalam 'menyapu bersih' para penipu.\n",
      "  → Jika Recall TINGGI: Sistem sangat efektif. Hampir tidak ada penipu yang bisa lolos, sehingga kerugian perusahaan bisa ditekan.\n",
      "  → Jika Recall RENDAH: Sistem banyak 'kebobolan'. Banyak transaksi penipuan yang berhasil lolos dan menyebabkan kerugian finansial bagi perusahaan.\n",
      "\n",
      "F1-Score              : 0.667\n",
      "  → Nilai gabungan yang menyeimbangkan antara Precision dan Recall.\n",
      "  → Mencari 'titik tengah' terbaik antara 'terlalu galak' (banyak salah blokir) dan 'terlalu longgar' (banyak fraud lolos).\n",
      "  → Ibaratnya, ini adalah nilai IPK si sistem. Sebuah angka tunggal untuk menilai apakah performanya seimbang dalam dua tugas penting tersebut.\n",
      "  → Berguna karena dalam kasus fraud, kita tidak bisa hanya fokus pada salah satunya saja.\n",
      "\n",
      "Specificity (TNR)     : 0.818\n",
      "  → Seberapa jago sistem dalam mengenali dan meloloskan PEMBELI JUJUR?\n",
      "  → Dari semua transaksi yang SEBENARNYA ASLI, berapa persen yang berhasil diloloskan tanpa masalah oleh sistem?\n",
      "  → Ini adalah metrik 'Kepuasan Pelanggan'. Jika nilainya tinggi, berarti sistem sangat jarang mengganggu transaksi dari pembeli yang sah.\n",
      "\n",
      "\n",
      "📈 METRIK UNTUK DATA TIDAK SEIMBANG (IMBALANCED):\n",
      "   (Sangat relevan untuk kasus fraud dimana transaksi asli jauh > transaksi fraud)\n",
      "------------------------------------------------------------\n",
      "Balanced Accuracy     : 0.784\n",
      "  → Nilai Akurasi yang sudah 'diperbaiki' agar lebih adil untuk data timpang.\n",
      "  → Dihitung dengan merata-ratakan kemampuan sistem mendeteksi fraud (Recall) dan kemampuan sistem mengenali transaksi asli (Specificity).\n",
      "  → Mencegah sistem dapat nilai bagus hanya karena mayoritas transaksi adalah transaksi asli. Kinerja di dua sisi (asli vs fraud) dinilai setara.\n",
      "\n",
      "ROC-AUC               : 0.955\n",
      "  → Mengukur kemampuan sistem dalam MEMBEDAKAN antara transaksi fraud dan transaksi asli.\n",
      "  → Bayangkan sistem memberi 'skor kecurigaan' pada tiap transaksi. Nilai ini menunjukkan: Jika kita ambil 1 transaksi fraud dan 1 transaksi asli secara acak, seberapa besar kemungkinan sistem memberi skor lebih tinggi pada yang fraud?\n",
      "  → Nilai 1.0 = Sempurna. Nilai 0.5 = Tebakannya tidak lebih baik dari lempar koin.\n",
      "\n",
      "PR-AUC                : 0.917\n",
      "  → Mirip ROC-AUC, tapi ini adalah 'spesialis' untuk data yang sangat timpang seperti data fraud.\n",
      "  → Lebih fokus pada pertanyaan: 'Seberapa baik sistem dapat menemukan semua fraud (Recall) tanpa terlalu banyak salah tangkap (Precision)?'\n",
      "  → Karena tidak terpengaruh oleh jutaan transaksi asli yang mudah ditebak, metrik ini seringkali lebih menggambarkan performa asli model pada kasus fraud.\n",
      "\n",
      "Log Loss              : 0.381 (Makin kecil makin bagus)\n",
      "  → Menghukum sistem bukan hanya karena tebakannya salah, tapi juga karena 'terlalu percaya diri' saat salah.\n",
      "  → Sistem yang baik tidak hanya menebak 'fraud' atau 'asli', tapi juga memberikan tingkat keyakinan (probabilitas).\n",
      "  → Contoh: Jika sistem dengan yakin 99% bilang sebuah transaksi itu fraud, padahal ternyata asli, ia akan dapat 'hukuman' (nilai Log Loss) yang sangat besar.\n"
     ]
    }
   ],
   "source": [
    "# Anggap saja model kita adalah sebuah SISTEM PENYARING OTOMATIS.\n",
    "# Transaksi Asli/Sah = Transaksi dari pembeli jujur.\n",
    "# Transaksi Fraud = Transaksi dari penipu.\n",
    "\n",
    "# TP (True Positive)  : Sistem TEPAT memblokir transaksi penipu. ✅\n",
    "# TN (True Negative)  : Sistem TEPAT meloloskan transaksi pembeli jujur. ✅\n",
    "# FP (False Positive) : Sistem SALAH memblokir transaksi pembeli jujur. (False Alarm 🚨)\n",
    "# FN (False Negative) : Sistem KECOLONGAN, transaksi penipu malah diloloskan. (Fraud Lolos 💸)\n",
    "\n",
    "print(f\"Accuracy (Akurasi)    : {accuracy:.3f}\")\n",
    "print(\"  → Seberapa sering tebakan sistem benar secara keseluruhan (baik saat memblokir penipu maupun meloloskan pembeli jujur).\")\n",
    "print(\"  → Ibarat nilai rapor umum sistem.\")\n",
    "print(\"  → PERHATIAN: Akurasi bisa menipu jika jumlah transaksi asli jauh lebih banyak dari transaksi fraud. Sistem bisa dapat nilai 99% hanya dengan meloloskan semua transaksi, padahal semua penipunya ikut lolos.\")\n",
    "\n",
    "print(f\"\\nPrecision (Presisi)     : {precision:.3f}\")\n",
    "print(\"  → Dari semua transaksi yang DIBLOKIR oleh sistem, berapa persen yang BENAR-BENAR penipuan?\")\n",
    "print(\"  → Mengukur KUALITAS pemblokiran. Jangan sampai sering salah blokir!\")\n",
    "print(\"  → Jika Precision TINGGI: Sistem sangat bisa diandalkan. Saat ia memblokir sesuatu, hampir pasti itu penipuan. Ini penting agar tidak membuat pelanggan jujur kecewa karena transaksinya ditolak.\")\n",
    "print(\"  → Jika Precision RENDAH: Sistem terlalu 'parno'. Banyak transaksi dari pembeli jujur yang ikut diblokir. Ini menyebabkan pengalaman belanja yang buruk dan banyak komplain pelanggan.\")\n",
    "\n",
    "print(f\"\\nRecall (Daya Jangkau)   : {recall:.3f}\")\n",
    "print(\"  → Dari semua transaksi penipuan yang SEBENARNYA terjadi, berapa persen yang berhasil DISARING/DIBLOKIR oleh sistem?\")\n",
    "print(\"  → Mengukur KEMAMPUAN sistem dalam 'menyapu bersih' para penipu.\")\n",
    "print(\"  → Jika Recall TINGGI: Sistem sangat efektif. Hampir tidak ada penipu yang bisa lolos, sehingga kerugian perusahaan bisa ditekan.\")\n",
    "print(\"  → Jika Recall RENDAH: Sistem banyak 'kebobolan'. Banyak transaksi penipuan yang berhasil lolos dan menyebabkan kerugian finansial bagi perusahaan.\")\n",
    "\n",
    "print(f\"\\nF1-Score              : {f1:.3f}\")\n",
    "print(\"  → Nilai gabungan yang menyeimbangkan antara Precision dan Recall.\")\n",
    "print(\"  → Mencari 'titik tengah' terbaik antara 'terlalu galak' (banyak salah blokir) dan 'terlalu longgar' (banyak fraud lolos).\")\n",
    "print(\"  → Ibaratnya, ini adalah nilai IPK si sistem. Sebuah angka tunggal untuk menilai apakah performanya seimbang dalam dua tugas penting tersebut.\")\n",
    "print(\"  → Berguna karena dalam kasus fraud, kita tidak bisa hanya fokus pada salah satunya saja.\")\n",
    "\n",
    "print(f\"\\nSpecificity (TNR)     : {specificity:.3f}\")\n",
    "print(\"  → Seberapa jago sistem dalam mengenali dan meloloskan PEMBELI JUJUR?\")\n",
    "print(\"  → Dari semua transaksi yang SEBENARNYA ASLI, berapa persen yang berhasil diloloskan tanpa masalah oleh sistem?\")\n",
    "print(\"  → Ini adalah metrik 'Kepuasan Pelanggan'. Jika nilainya tinggi, berarti sistem sangat jarang mengganggu transaksi dari pembeli yang sah.\")\n",
    "\n",
    "print(\"\\n\\n📈 METRIK UNTUK DATA TIDAK SEIMBANG (IMBALANCED):\")\n",
    "print(\"   (Sangat relevan untuk kasus fraud dimana transaksi asli jauh > transaksi fraud)\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Balanced Accuracy     : {balanced_acc:.3f}\")\n",
    "print(\"  → Nilai Akurasi yang sudah 'diperbaiki' agar lebih adil untuk data timpang.\")\n",
    "print(\"  → Dihitung dengan merata-ratakan kemampuan sistem mendeteksi fraud (Recall) dan kemampuan sistem mengenali transaksi asli (Specificity).\")\n",
    "print(\"  → Mencegah sistem dapat nilai bagus hanya karena mayoritas transaksi adalah transaksi asli. Kinerja di dua sisi (asli vs fraud) dinilai setara.\")\n",
    "\n",
    "print(f\"\\nROC-AUC               : {roc_auc:.3f}\")\n",
    "print(\"  → Mengukur kemampuan sistem dalam MEMBEDAKAN antara transaksi fraud dan transaksi asli.\")\n",
    "print(\"  → Bayangkan sistem memberi 'skor kecurigaan' pada tiap transaksi. Nilai ini menunjukkan: Jika kita ambil 1 transaksi fraud dan 1 transaksi asli secara acak, seberapa besar kemungkinan sistem memberi skor lebih tinggi pada yang fraud?\")\n",
    "print(\"  → Nilai 1.0 = Sempurna. Nilai 0.5 = Tebakannya tidak lebih baik dari lempar koin.\")\n",
    "\n",
    "print(f\"\\nPR-AUC                : {pr_auc:.3f}\")\n",
    "print(\"  → Mirip ROC-AUC, tapi ini adalah 'spesialis' untuk data yang sangat timpang seperti data fraud.\")\n",
    "print(\"  → Lebih fokus pada pertanyaan: 'Seberapa baik sistem dapat menemukan semua fraud (Recall) tanpa terlalu banyak salah tangkap (Precision)?'\")\n",
    "print(\"  → Karena tidak terpengaruh oleh jutaan transaksi asli yang mudah ditebak, metrik ini seringkali lebih menggambarkan performa asli model pada kasus fraud.\")\n",
    "\n",
    "print(f\"\\nLog Loss              : {ll:.3f} (Makin kecil makin bagus)\")\n",
    "print(\"  → Menghukum sistem bukan hanya karena tebakannya salah, tapi juga karena 'terlalu percaya diri' saat salah.\")\n",
    "print(\"  → Sistem yang baik tidak hanya menebak 'fraud' atau 'asli', tapi juga memberikan tingkat keyakinan (probabilitas).\")\n",
    "print(\"  → Contoh: Jika sistem dengan yakin 99% bilang sebuah transaksi itu fraud, padahal ternyata asli, ia akan dapat 'hukuman' (nilai Log Loss) yang sangat besar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e07d63b6-7ddf-47d1-b92c-bab8e9954b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Asumsi Biaya Bisnis ===\n",
      "Kerugian per Fraud Lolos (FN) : Rp 5,000,000\n",
      "Biaya per Review Manual (FP)  : Rp 150,000\n",
      "\n",
      "--- [ Skenario A: Fokus RECALL TINGGI (Threshold Rendah) ] ---\n",
      "Dengan threshold = 0.45, model menjadi lebih 'agresif':\n",
      "  → Recall: 1.00 (Naik, bagus!) | Precision: 0.67 (Turun, risiko)\n",
      "  → Fraud Lolos (FN)       : 0 transaksi → Kerugian: Rp 0\n",
      "  → Salah Blokir (FP)      : 2 transaksi → Biaya   : Rp 300,000\n",
      "  → TOTAL POTENSI KERUGIAN : Rp 300,000\n",
      "\n",
      "  (+) PRO: Sebagian besar fraud tertangkap, meminimalkan kerugian besar.\n",
      "  (-) KONTRA: Biaya operasional untuk review naik & berisiko mengganggu banyak pelanggan jujur.\n",
      "\n",
      "--- [ Skenario B: Fokus PRECISION TINGGI (Threshold Tinggi) ] ---\n",
      "Dengan threshold = 0.7, model menjadi lebih 'konservatif':\n",
      "  → Recall: 0.50 (Turun, bahaya!) | Precision: 1.00 (Naik, bagus!)\n",
      "  → Fraud Lolos (FN)       : 2 transaksi → Kerugian: Rp 10,000,000\n",
      "  → Salah Blokir (FP)      : 0 transaksi → Biaya   : Rp 0\n",
      "  → TOTAL POTENSI KERUGIAN : Rp 10,000,000\n",
      "\n",
      "  (+) PRO: Sangat jarang mengganggu pelanggan jujur, biaya review rendah.\n",
      "  (-) KONTRA: Risiko kebobolan fraud bernilai besar sangat tinggi.\n",
      "\n",
      "--- [ Skenario C: Pendekatan Seimbang (Threshold Default) ] ---\n",
      "Dengan threshold = 0.50, performa awal adalah:\n",
      "  → Recall: 0.75 | Precision: 0.60\n",
      "  → TOTAL POTENSI KERUGIAN : Rp 5,300,000\n",
      "\n",
      "================================================================\n",
      "             PERBANDINGAN TOTAL POTENSI KERUGIAN\n",
      "================================================================\n",
      "| Strategi                 | Threshold | Total Kerugian   |\n",
      "|--------------------------|-----------|------------------|\n",
      "| A: Fokus Recall (Agresif)|   0.45    | Rp    300,000     |\n",
      "| C: Seimbang (Default)    |   0.50    | Rp   5,300,000    |\n",
      "| B: Fokus Precision (Konservatif)|   0.70    | Rp   10,000,000   |\n",
      "================================================================\n",
      "\n",
      "💡 Pertimbangan Bisnis:\n",
      "Tidak ada threshold yang 'sempurna', yang ada adalah threshold yang 'optimal' sesuai tujuan bisnis.\n",
      "  - Jika bisnis sedang fokus menekan kerugian finansial akibat fraud (misalnya saat ada serangan), maka strategi A (Fokus Recall) lebih masuk akal meskipun biaya operasional naik.\n",
      "  - Jika prioritas utama adalah menjaga pengalaman dan kepuasan pelanggan agar tidak terganggu, maka strategi B (Fokus Precision) bisa dipilih, dengan kesadaran bahwa risiko kebobolan fraud lebih tinggi.\n",
      "\n",
      "Analisis seperti ini membantu tim untuk menentukan 'sweet spot' atau titik threshold yang memberikan kerugian total paling minimal bagi perusahaan.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# 3) ANALISIS BIAYA & SIMULASI STRATEGI BISNIS\n",
    "#    Menghitung potensi kerugian finansial berdasarkan keputusan model.\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Asumsikan biaya-biaya berikut (dalam Rupiah):\n",
    "# Ini adalah estimasi yang harus divalidasi oleh tim bisnis/keuangan.\n",
    "\n",
    "# Rata-rata kerugian jika 1 transaksi fraud berhasil lolos (False Negative).\n",
    "# Misalnya, nilai transaksi rata-rata yang hilang.\n",
    "avg_fraud_loss = 5000000  # Rp 5.000.000\n",
    "\n",
    "# Biaya untuk setiap investigasi manual pada transaksi yang ditandai (False Positive).\n",
    "# Meliputi waktu analis, tool, atau potensi kerugian karena menunda transaksi pelanggan sah.\n",
    "cost_of_review = 150000   # Rp 150.000\n",
    "\n",
    "print(\"=== Asumsi Biaya Bisnis ===\")\n",
    "print(f\"Kerugian per Fraud Lolos (FN) : Rp {avg_fraud_loss:,}\")\n",
    "print(f\"Biaya per Review Manual (FP)  : Rp {cost_of_review:,}\\n\")\n",
    "\n",
    "# ---\n",
    "# Skenario A: Fokus KEJAR RECALL (Tim \"Anti-Kecolongan\")\n",
    "# Kita menurunkan threshold agar lebih sensitif dan menangkap lebih banyak fraud.\n",
    "# Konsekuensi: Akan ada lebih banyak False Positive (salah tuduh).\n",
    "# ---\n",
    "print(\"--- [ Skenario A: Fokus RECALL TINGGI (Threshold Rendah) ] ---\")\n",
    "thr_recall = 0.45  # Turunkan threshold agar lebih banyak transaksi dianggap berisiko\n",
    "\n",
    "# Hitung ulang prediksi, metrik, dan kerugian\n",
    "y_pred_recall = (y_score >= thr_recall).astype(int)\n",
    "TN_r, FP_r, FN_r, TP_r = confusion_matrix(y_true, y_pred_recall).ravel()\n",
    "precision_r = precision_score(y_true, y_pred_recall, zero_division=0)\n",
    "recall_r = recall_score(y_true, y_pred_recall, zero_division=0)\n",
    "\n",
    "# Hitung total kerugian finansial untuk skenario ini\n",
    "loss_from_missed_fraud = FN_r * avg_fraud_loss\n",
    "loss_from_reviews = FP_r * cost_of_review\n",
    "total_loss_recall = loss_from_missed_fraud + loss_from_reviews\n",
    "\n",
    "print(f\"Dengan threshold = {thr_recall}, model menjadi lebih 'agresif':\")\n",
    "print(f\"  → Recall: {recall_r:.2f} (Naik, bagus!) | Precision: {precision_r:.2f} (Turun, risiko)\")\n",
    "print(f\"  → Fraud Lolos (FN)       : {FN_r} transaksi → Kerugian: Rp {loss_from_missed_fraud:,}\")\n",
    "print(f\"  → Salah Blokir (FP)      : {FP_r} transaksi → Biaya   : Rp {loss_from_reviews:,}\")\n",
    "print(f\"  → TOTAL POTENSI KERUGIAN : Rp {total_loss_recall:,}\\n\")\n",
    "print(\"  (+) PRO: Sebagian besar fraud tertangkap, meminimalkan kerugian besar.\")\n",
    "print(\"  (-) KONTRA: Biaya operasional untuk review naik & berisiko mengganggu banyak pelanggan jujur.\\n\")\n",
    "\n",
    "\n",
    "# ---\n",
    "# Skenario B: Fokus JAGA PRECISION (Tim \"Anti-Salah-Tuduh\")\n",
    "# Kita menaikkan threshold agar hanya transaksi yang SANGAT MENCURIGAKAN yang diblokir.\n",
    "# Konsekuensi: Akan ada lebih banyak False Negative (fraud yang lolos).\n",
    "# ---\n",
    "print(\"--- [ Skenario B: Fokus PRECISION TINGGI (Threshold Tinggi) ] ---\")\n",
    "thr_precision = 0.70 # Naikkan threshold, model hanya akan yakin pada skor yang sangat tinggi\n",
    "\n",
    "# Hitung ulang prediksi, metrik, dan kerugian\n",
    "y_pred_precision = (y_score >= thr_precision).astype(int)\n",
    "TN_p, FP_p, FN_p, TP_p = confusion_matrix(y_true, y_pred_precision).ravel()\n",
    "precision_p = precision_score(y_true, y_pred_precision, zero_division=0)\n",
    "recall_p = recall_score(y_true, y_pred_precision, zero_division=0)\n",
    "\n",
    "# Hitung total kerugian finansial untuk skenario ini\n",
    "loss_from_missed_fraud_p = FN_p * avg_fraud_loss\n",
    "loss_from_reviews_p = FP_p * cost_of_review\n",
    "total_loss_precision = loss_from_missed_fraud_p + loss_from_reviews_p\n",
    "\n",
    "print(f\"Dengan threshold = {thr_precision}, model menjadi lebih 'konservatif':\")\n",
    "print(f\"  → Recall: {recall_p:.2f} (Turun, bahaya!) | Precision: {precision_p:.2f} (Naik, bagus!)\")\n",
    "print(f\"  → Fraud Lolos (FN)       : {FN_p} transaksi → Kerugian: Rp {loss_from_missed_fraud_p:,}\")\n",
    "print(f\"  → Salah Blokir (FP)      : {FP_p} transaksi → Biaya   : Rp {loss_from_reviews_p:,}\")\n",
    "print(f\"  → TOTAL POTENSI KERUGIAN : Rp {total_loss_precision:,}\\n\")\n",
    "print(\"  (+) PRO: Sangat jarang mengganggu pelanggan jujur, biaya review rendah.\")\n",
    "print(\"  (-) KONTRA: Risiko kebobolan fraud bernilai besar sangat tinggi.\\n\")\n",
    "\n",
    "\n",
    "# ---\n",
    "# Skenario C: Pendekatan Seimbang (Menggunakan threshold default dari kode awal)\n",
    "# ---\n",
    "print(\"--- [ Skenario C: Pendekatan Seimbang (Threshold Default) ] ---\")\n",
    "loss_from_missed_fraud_def = FN * avg_fraud_loss\n",
    "loss_from_reviews_def = FP * cost_of_review\n",
    "total_loss_default = loss_from_missed_fraud_def + loss_from_reviews_def\n",
    "print(f\"Dengan threshold = {thr_default:.2f}, performa awal adalah:\")\n",
    "print(f\"  → Recall: {recall:.2f} | Precision: {precision:.2f}\")\n",
    "print(f\"  → TOTAL POTENSI KERUGIAN : Rp {total_loss_default:,}\\n\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4) KESIMPULAN & REKOMENDASI\n",
    "# -----------------------------\n",
    "print(\"================================================================\")\n",
    "print(\"             PERBANDINGAN TOTAL POTENSI KERUGIAN\")\n",
    "print(\"================================================================\")\n",
    "print(f\"| Strategi                 | Threshold | Total Kerugian   |\")\n",
    "print(f\"|--------------------------|-----------|------------------|\")\n",
    "print(f\"| A: Fokus Recall (Agresif)| {thr_recall:^9.2f} | Rp {total_loss_recall:^14,d} |\")\n",
    "print(f\"| C: Seimbang (Default)    | {thr_default:^9.2f} | Rp {total_loss_default:^14,d} |\")\n",
    "print(f\"| B: Fokus Precision (Konservatif)| {thr_precision:^9.2f} | Rp {total_loss_precision:^14,d} |\")\n",
    "print(\"================================================================\\n\")\n",
    "\n",
    "print(\"💡 Pertimbangan Bisnis:\")\n",
    "print(\"Tidak ada threshold yang 'sempurna', yang ada adalah threshold yang 'optimal' sesuai tujuan bisnis.\")\n",
    "print(\"  - Jika bisnis sedang fokus menekan kerugian finansial akibat fraud (misalnya saat ada serangan), maka strategi A (Fokus Recall) lebih masuk akal meskipun biaya operasional naik.\")\n",
    "print(\"  - Jika prioritas utama adalah menjaga pengalaman dan kepuasan pelanggan agar tidak terganggu, maka strategi B (Fokus Precision) bisa dipilih, dengan kesadaran bahwa risiko kebobolan fraud lebih tinggi.\")\n",
    "print(\"\\nAnalisis seperti ini membantu tim untuk menentukan 'sweet spot' atau titik threshold yang memberikan kerugian total paling minimal bagi perusahaan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917ffe7b-4a86-4b28-9cf4-d246b9c84134",
   "metadata": {},
   "source": [
    "## 3.4 Model catalog: academic and practical view\n",
    "\n",
    "Below is a balanced catalog that covers baselines, interpretable models, and high-performance models. The best practice is to start with strong **benchmarks** then escalate in complexity.\n",
    "\n",
    "---\n",
    "\n",
    "### 1) Linear and Probabilistic Models\n",
    "\n",
    "These models find simple, often linear relationships in your data. They are fast, easy to understand, and provide a great starting point for any classification task.\n",
    "\n",
    "- **Logistic Regression**\n",
    "  - **Definition:** Thinks of this as a statistical tool for predicting a yes/no outcome (e.g., will a customer default?). It calculates the probability of an event by taking a weighted sum of input variables (like income, age, loan amount). The \"coefficients\" or weights tell you how much each factor influences the outcome, and in which direction.\n",
    "  - **When to Use:** An excellent baseline for binary classification problems like fraud detection or credit approval. It's fast, robust, and the results are easy to explain to stakeholders. It works best when your financial metrics are scaled to a similar range (e.g., 0 to 1) and can be tweaked with regularization (L1 or L2) to handle a large number of features without overfitting. Note that it assumes a linear relationship between the inputs and the outcome.\n",
    "\n",
    "- **Linear Discriminant Analysis (LDA)**\n",
    "  - **Definition:** LDA is a method that finds a combination of your financial metrics that best separates two or more groups (e.g., profitable vs. non-profitable companies). It does this by projecting your data onto a lower-dimensional space, maximizing the distance between the groups.\n",
    "  - **When to Use:** It's very fast and effective when your numerical data (like financial ratios) is well-behaved and follows a bell-curve (normal) distribution. It can be a strong performer in situations where its statistical assumptions hold true.\n",
    "\n",
    "- **Naive Bayes**\n",
    "  - **Definition:** This model uses probability (specifically Bayes' Theorem) to classify data. It makes a \"naive\" but powerful assumption that all input features are independent of each other (e.g., that a company's revenue has no bearing on its number of employees).\n",
    "  - **When to Use:** It's extremely fast and a great first model to try, especially for analyzing text like news articles for sentiment analysis or classifying transaction descriptions. Despite its simple assumption, it often performs surprisingly well in practice.\n",
    "\n",
    "---\n",
    "\n",
    "### 2) Distance and Margin-Based Models\n",
    "\n",
    "These models classify data points based on their proximity to other points or to a dividing boundary.\n",
    "\n",
    "- **k-Nearest Neighbors (k-NN)**\n",
    "  - **Definition:** A simple and intuitive model that classifies a new data point based on the majority class of its \"k\" closest neighbors. Think of it as \"judging a company by the company it keeps.\" If a new loan applicant's financial profile is very similar to 5 previous applicants who all defaulted, k-NN would predict a default.\n",
    "  - **When to Use:** Good for smaller, clean datasets where data points with similar features tend to have similar outcomes. It's easy to understand but can become very slow for making predictions on large datasets and can struggle when you have a high number of features (the \"curse of dimensionality\"). Requires feature scaling.\n",
    "\n",
    "- **Support Vector Machines (SVM)**\n",
    "  - **Definition:** An SVM seeks to find the best possible \"line\" or boundary that separates different classes of data. It does this by maximizing the margin, or the gap, between the closest data points of each class (the \"support vectors\"). Using a \"kernel trick,\" it can even find complex, non-linear boundaries.\n",
    "  - **When to Use:** A powerful choice for medium-sized, well-structured datasets, such as predicting stock price direction (up or down). It requires feature scaling and careful tuning of its parameters, and can be computationally intensive on very large datasets.\n",
    "\n",
    "---\n",
    "\n",
    "### 3) Tree-Based Models\n",
    "\n",
    "These models use a series of \"if-then\" rules to make predictions, forming a structure that looks like a tree.\n",
    "\n",
    "- **Decision Tree**\n",
    "  - **Definition:** Creates a flowchart of questions to arrive at a classification. For example: \"Is the P/E ratio > 20? If yes, is the debt-to-equity ratio < 0.5? If no, classify as 'Buy'.\" The resulting tree is highly transparent and easy to interpret.\n",
    "  - **When to Use:** Excellent when you need to explain the model's logic clearly. They are fast but, on their own, can easily memorize the training data (overfit). They are most often used as the building blocks for more powerful \"ensemble\" models below.\n",
    "\n",
    "- **Random Forest**\n",
    "  - **Definition:** Instead of relying on one decision tree, a Random Forest builds a large number of them. Each tree is trained on a random sample of the data and considers only a random subset of features. The final prediction is determined by a majority vote from all the trees in the \"forest.\"\n",
    "  - **When to Use:** A fantastic default model for many problems. It's powerful, handles complex relationships and interactions automatically, is robust to outliers, and requires minimal tuning. Great for tasks like customer churn prediction or asset valuation. Its main drawback is being less directly interpretable than a single tree.\n",
    "\n",
    "- **Extra Trees (Extremely Randomized Trees)**\n",
    "  - **Definition:** A variation of Random Forest that adds another layer of randomness. When splitting a node, instead of searching for the best possible split, it tests a few random splits and picks the best among them. This reduces variance and speeds up training.\n",
    "  - **When to Use:** A good alternative to try alongside a Random Forest. It is often faster to train and can sometimes yield better performance.\n",
    "\n",
    "- **Gradient Boosting Trees (XGBoost, LightGBM, CatBoost)**\n",
    "  - **Definition:** The current state-of-the-art for many tabular data problems. This technique builds trees sequentially, where each new tree is trained to correct the errors made by the previous ones. It's like assembling a team of specialists, where each one focuses on the hardest cases the previous one got wrong.\n",
    "  - **When to Use:** When you need the highest possible performance on structured data like financial statements, market data, or transaction logs.\n",
    "    - **XGBoost:** The well-established, reliable, and highly customizable standard.\n",
    "    - **LightGBM:** Known for its incredible speed, especially on very large datasets.\n",
    "    - **CatBoost:** Shines when you have a lot of categorical features (e.g., industry, country, product type), as it can handle them automatically and effectively.\n",
    "  - These models require careful tuning and cross-validation to prevent overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### 4) Neural Models for Tabular Data\n",
    "\n",
    "These models are inspired by the structure of the human brain and can learn very complex patterns.\n",
    "\n",
    "- **Multilayer Perceptron (MLP)**\n",
    "  - **Definition:** A classic type of neural network that uses interconnected layers of \"neurons\" to learn complex, non-linear patterns in the data. It's considered a universal approximator, meaning it can theoretically model any continuous function.\n",
    "  - **When to Use:** While tree-based models often perform better on standard tabular financial data, an MLP can be a good choice if you have a very large dataset or if you suspect there are intricate underlying patterns that other models miss. They require careful feature scaling, tuning of the network structure, and regularization.\n",
    "\n",
    "---\n",
    "\n",
    "### 5) Probabilistic and Calibrated Outputs\n",
    "\n",
    "Ensuring the model's probability scores are trustworthy.\n",
    "\n",
    "- **Calibrated Classifiers**\n",
    "  - **Definition:** A process that adjusts a model's output scores to ensure they represent true probabilities. For example, when a calibrated model predicts an 80% probability of default, it means that out of 100 loans with that score, about 80 will actually default. Models like SVMs or even boosted trees can be poorly calibrated out-of-the-box.\n",
    "  - **When to Use:** This is **critical** when your business decision depends on the probability value itself, not just the final classification. Examples include calculating expected credit loss, setting insurance premiums, or pricing financial instruments based on risk. Calibration should always be done on a validation dataset that the model hasn't seen during training.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81c9172-dab3-4013-abea-3584e6c338f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "028ba3b9-f206-4d58-972e-6098325f0890",
   "metadata": {},
   "source": [
    "## 3.5 Imbalanced learning strategies\n",
    "\n",
    "When positive class is rare (fraud, default), accuracy can mislead.\n",
    "\n",
    "Tools  \n",
    "- **Class weights**: make errors on minority class count more.  \n",
    "- **Resampling**: oversample minority (RandomOverSampler, SMOTE) or undersample majority.  \n",
    "- **Threshold moving**: raise or lower the decision threshold to meet cost or recall targets.  \n",
    "- **Appropriate metrics**: PR-AUC, F1, recall at fixed precision, cost-based evaluation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9686c0-54a5-43f7-ab4b-cef354168417",
   "metadata": {},
   "source": [
    "## 3.6 Interpretability and accountability\n",
    "\n",
    "- **Global explanations**  \n",
    "  - Logistic regression coefficients and odds ratios.  \n",
    "  - Tree feature importances.  \n",
    "  - Permutation importance for model-agnostic insight.  \n",
    "  - SHAP values to explain contributions per feature.\n",
    "\n",
    "- **Local explanations**  \n",
    "  - Explain a specific decision for auditability.\n",
    "\n",
    "- **Fairness and compliance**  \n",
    "  - Avoid sensitive attributes unless explicitly permitted and justified.  \n",
    "  - Monitor disparate impact.  \n",
    "  - Keep documentation of data sources, preprocessing, versions, and decisions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f59ba-888b-4336-a70d-19dece4bf80c",
   "metadata": {},
   "source": [
    "## 3.7 Robust practice: from notebook to production\n",
    "\n",
    "- **Cross-validation**: use stratified k-fold for stable estimates.  \n",
    "- **Hyperparameter search**: start with simple grids or randomized search, then narrow.  \n",
    "- **Pipelines**: include scaling and encoding inside the pipeline to prevent leakage.  \n",
    "- **Out-of-time validation**: for temporal data (quarters), validate on a future slice.  \n",
    "- **Monitoring**: track data drift, performance decay, calibration drift.  \n",
    "- **Rollback plan**: maintain a safe baseline model and alerts.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.8 Suggested benchmarking protocol\n",
    "\n",
    "1) **Sanity checks**  \n",
    "   - DummyClassifier (majority).  \n",
    "   - Single-feature threshold.\n",
    "\n",
    "2) **Interpretable baseline**  \n",
    "   - Logistic Regression with standardized numeric features and one-hot categoricals.  \n",
    "   - Collect coefficients and odds ratios to explain drivers.\n",
    "\n",
    "3) **Strong default**  \n",
    "   - Random Forest with reasonable depth and estimators.  \n",
    "   - Compare metrics and calibration.\n",
    "\n",
    "4) **High-performance candidate**  \n",
    "   - Gradient Boosting (LightGBM or XGBoost) with early stopping.  \n",
    "   - Tune learning rate, max depth or leaves, regularization.\n",
    "\n",
    "5) **Pick by cost and constraints**  \n",
    "   - If explanations and speed to sign-off matter: Logistic Regression or small trees with clear rules.  \n",
    "   - If predictive power is paramount and auditability can be handled: Gradient Boosting.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.9 Quick cheat sheet\n",
    "\n",
    "| Model | Use when | Strengths | Caveats | Quick setup |\n",
    "|---|---|---|---|---|\n",
    "| Dummy baseline | Always | Sets floor | None | Majority class baseline |\n",
    "| Logistic Regression | Need interpretability and speed | Simple, fast, well-calibrated with tuning | Needs scaling, linear boundary | Standardize, L2 penalty, class_weight if needed |\n",
    "| LDA | Numeric, near-Gaussian | Very fast, solid if assumptions hold | Sensitive to covariance assumptions | Standardize, check covariance |\n",
    "| Naive Bayes | Text or counts | Blazing fast | Independence assumption | MultinomialNB for counts |\n",
    "| k-NN | Small to medium data | Simple, non-parametric | Slow at prediction, needs scaling | Scale, tune k via CV |\n",
    "| SVM (RBF) | Medium-sized clean data | Strong margins | Tuning C and gamma | Scale, grid C and gamma |\n",
    "| Decision Tree | Rules needed | Transparent rules | Overfits without limits | Limit depth, prune |\n",
    "| Random Forest | General tabular default | Robust, low tuning, handles mixes | Less interpretable | 200 trees, limit depth, class_weight |\n",
    "| Extra Trees | Similar to RF, faster | Often strong | Similar caveats | 400 trees, shallow to medium depth |\n",
    "| LightGBM/XGBoost | Best tabular accuracy | State-of-the-art | Tuning required | Early stopping, tune depth and learning rate |\n",
    "| CatBoost | Many categoricals | Native categorical handling | Slower than LightGBM | Use default with categorical features |\n",
    "| MLP | Very large data or special structure | Flexible | Tuning, needs scaling | Scale, small hidden layers, early stopping |\n",
    "\n",
    "---\n",
    "\n",
    "## 3.10 Glossary\n",
    "\n",
    "- **Feature**: input variable.  \n",
    "- **Label**: target variable to predict.  \n",
    "- **Overfitting**: great on train, poor on test.  \n",
    "- **Underfitting**: poor on both train and test.  \n",
    "- **Calibration**: predicted probabilities match observed frequencies.  \n",
    "- **Stratification**: keep class ratios similar across folds or splits.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.11 Accounting-focused examples\n",
    "\n",
    "- **Business viability (`isOpen`)**  \n",
    "  Inputs: revenue trend, expenses ratio, cash balance, industry, age.  \n",
    "  Useful models: Logistic Regression for explainability, Random Forest or LightGBM for lift.  \n",
    "  Metric: balanced accuracy, recall for closures, or cost-based threshold.\n",
    "\n",
    "- **Loan default**  \n",
    "  Inputs: credit score, DTI, payment history, collateral value.  \n",
    "  Useful models: Gradient Boosting with calibration.  \n",
    "  Metric: ROC-AUC, PR-AUC, expected loss.\n",
    "\n",
    "- **Fraud detection**  \n",
    "  Inputs: transaction amount, merchant category, device ID, velocity features.  \n",
    "  Useful models: Gradient Boosting, calibrated probabilities, cost-sensitive threshold.  \n",
    "  Metric: precision at top-k, recall at fixed false positive rate, cost minimization.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.12 Minimal workflow you can reuse\n",
    "\n",
    "1) Define target and features.  \n",
    "2) Split into train and test (stratified).  \n",
    "3) Build pipeline with: imputers, encoders, scaler.  \n",
    "4) Train baseline (Logistic Regression).  \n",
    "5) Train strong default (Random Forest).  \n",
    "6) If needed, train boosted trees with early stopping.  \n",
    "7) Evaluate with proper metrics and pick thresholds by cost.  \n",
    "8) Document model and release with monitoring.\n",
    "\n",
    "---\n",
    "\n",
    "**Learning outcomes**  \n",
    "By the end of this part, students will be able to:  \n",
    "- Frame a classification problem that aligns with an accounting decision.  \n",
    "- Build and evaluate baseline and benchmark models.  \n",
    "- Interpret results using the right metrics and thresholds.  \n",
    "- Explain model trade-offs to non-technical stakeholders.  \n",
    "- Prepare a model for responsible deployment with monitoring and documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "debda03e-f0fc-4259-82db-6a03d05a4b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250831_124759\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🚀 AUTOGLUON AUTOML - SIMPLE & FIXED VERSION\n",
      "================================================================================\n",
      "\n",
      "📊 Dataset Info:\n",
      "Training samples: 40000\n",
      "Test samples: 10000\n",
      "Features: 6058\n",
      "Target distribution: {0: 0.8, 1: 0.2}\n",
      "\n",
      "================================================================================\n",
      "🔄 TRAINING MODELS WITH AUTOGLUON (Simplified Settings)\n",
      "================================================================================\n",
      "\n",
      "Training AutoGluon with simplified settings...\n",
      "This should take 2-3 minutes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Data size prior to feature transformation consumes 28.1% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Training completed in 55.3 seconds\n",
      "\n",
      "================================================================================\n",
      "📈 MODEL EVALUATION RESULTS\n",
      "================================================================================\n",
      "\n",
      "🎯 BASIC METRICS:\n",
      "----------------------------------------\n",
      "Accuracy    : 1.000\n",
      "Precision   : 1.000  (dari yang diprediksi fraud, berapa % benar)\n",
      "Recall      : 1.000  (dari semua fraud, berapa % tertangkap)\n",
      "F1-Score    : 1.000  (keseimbangan precision & recall)\n",
      "Specificity : 1.000  (dari semua normal, berapa % dikenali normal)\n",
      "ROC-AUC     : 1.000  (kualitas ranking skor fraud)\n",
      "\n",
      "📊 CONFUSION MATRIX:\n",
      "----------------------------------------\n",
      "True Negatives  (TN): 7,999  -> Normal, diprediksi Normal ✓\n",
      "False Positives (FP): 1  -> Normal, diprediksi Fraud ✗\n",
      "False Negatives (FN): 0  -> Fraud, diprediksi Normal ✗\n",
      "True Positives  (TP): 2,000  -> Fraud, diprediksi Fraud ✓\n",
      "\n",
      "================================================================================\n",
      "🏆 MODEL LEADERBOARD\n",
      "================================================================================\n",
      "\n",
      "Models Trained:\n",
      "                 model  score_test  pred_time_test  fit_time\n",
      "0             CatBoost     1.00000        0.034854  8.194745\n",
      "1             LightGBM     1.00000        0.041689  3.163693\n",
      "2           ExtraTrees     1.00000        0.077699  2.384621\n",
      "3         RandomForest     0.99975        0.082049  4.277421\n",
      "4          LinearModel     0.99975        0.086239  2.291114\n",
      "5              XGBoost     0.99975        0.141108  5.629698\n",
      "6  WeightedEnsemble_L2     0.99975        0.148263  5.773678\n",
      "\n",
      "================================================================================\n",
      "🥇 BEST MODEL DETAILS\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TabularPredictor' object has no attribute 'get_model_best'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 136\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🥇 BEST MODEL DETAILS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m--> 136\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_best\u001b[49m()\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Model info\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TabularPredictor' object has no attribute 'get_model_best'"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"🚀 AUTOGLUON AUTOML - SIMPLE & FIXED VERSION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ===========================\n",
    "# PREPARE DATA FOR AUTOGLUON\n",
    "# ===========================\n",
    "\n",
    "# Combine preprocessed features with target for AutoGluon\n",
    "train_data = pd.DataFrame(X_train_ready)\n",
    "train_data['target'] = y_train.values\n",
    "\n",
    "test_data = pd.DataFrame(X_test_ready)\n",
    "test_data['target'] = y_test.values\n",
    "\n",
    "print(f\"\\n📊 Dataset Info:\")\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "print(f\"Features: {X_train_ready.shape[1]}\")\n",
    "print(f\"Target distribution: {y_train.value_counts(normalize=True).round(3).to_dict()}\")\n",
    "\n",
    "# ===========================\n",
    "# TRAIN WITH AUTOGLUON (SIMPLIFIED)\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"🔄 TRAINING MODELS WITH AUTOGLUON (Simplified Settings)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Initialize predictor with simpler settings\n",
    "predictor = TabularPredictor(\n",
    "    label='target',  # target column name\n",
    "    problem_type='binary',  # binary classification\n",
    "    eval_metric='f1',  # optimize for F1 score\n",
    "    verbosity=1  # less verbose to avoid clutter\n",
    ")\n",
    "\n",
    "# Train models with simpler configuration to avoid getting stuck\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"\\nTraining AutoGluon with simplified settings...\")\n",
    "print(\"This should take 2-3 minutes...\")\n",
    "\n",
    "# Use simpler preset and disable Ray parallelization\n",
    "predictor.fit(\n",
    "    train_data=train_data,\n",
    "    time_limit=180,  # 3 minutes time limit\n",
    "    presets='medium_quality',  # Simpler preset: 'medium_quality' instead of 'best_quality'\n",
    "    hyperparameters={  # Specify simpler models only\n",
    "        'GBM': {},  # LightGBM\n",
    "        'CAT': {},  # CatBoost  \n",
    "        'XGB': {},  # XGBoost\n",
    "        'RF': {},   # Random Forest\n",
    "        'XT': {},   # Extra Trees\n",
    "        'LR': {},   # Logistic Regression\n",
    "    },\n",
    "    num_bag_folds=0,  # Disable bagging to speed up\n",
    "    num_stack_levels=0,  # Disable stacking to avoid complexity\n",
    "    ag_args_fit={\n",
    "        'num_cpus': 1,  # Use only 1 CPU per model to avoid resource conflicts\n",
    "    }\n",
    ")\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "print(f\"\\n✅ Training completed in {train_time:.1f} seconds\")\n",
    "\n",
    "# ===========================\n",
    "# EVALUATE MODELS\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"📈 MODEL EVALUATION RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get predictions\n",
    "y_pred = predictor.predict(test_data.drop('target', axis=1))\n",
    "y_proba = predictor.predict_proba(test_data.drop('target', axis=1))[1]  # probability of positive class\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "print(\"\\n🎯 BASIC METRICS:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Accuracy    : {accuracy:.3f}\")\n",
    "print(f\"Precision   : {precision:.3f}  (dari yang diprediksi fraud, berapa % benar)\")\n",
    "print(f\"Recall      : {recall:.3f}  (dari semua fraud, berapa % tertangkap)\")\n",
    "print(f\"F1-Score    : {f1:.3f}  (keseimbangan precision & recall)\")\n",
    "print(f\"Specificity : {specificity:.3f}  (dari semua normal, berapa % dikenali normal)\")\n",
    "print(f\"ROC-AUC     : {roc_auc:.3f}  (kualitas ranking skor fraud)\")\n",
    "\n",
    "print(\"\\n📊 CONFUSION MATRIX:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"True Negatives  (TN): {tn:,}  -> Normal, diprediksi Normal ✓\")\n",
    "print(f\"False Positives (FP): {fp:,}  -> Normal, diprediksi Fraud ✗\")\n",
    "print(f\"False Negatives (FN): {fn:,}  -> Fraud, diprediksi Normal ✗\")\n",
    "print(f\"True Positives  (TP): {tp:,}  -> Fraud, diprediksi Fraud ✓\")\n",
    "\n",
    "# ===========================\n",
    "# MODEL LEADERBOARD\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"🏆 MODEL LEADERBOARD\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Show leaderboard of all models tried\n",
    "leaderboard = predictor.leaderboard(test_data, silent=True)\n",
    "print(\"\\nModels Trained:\")\n",
    "print(leaderboard[['model', 'score_test', 'pred_time_test', 'fit_time']].to_string())\n",
    "\n",
    "# ===========================\n",
    "# BEST MODEL INFO\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"🥇 BEST MODEL DETAILS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "best_model = predictor.get_model_best()\n",
    "print(f\"Best Model: {best_model}\")\n",
    "\n",
    "# Model info\n",
    "model_info = predictor.info()\n",
    "print(f\"Total models trained: {model_info['num_models_trained']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ AUTOGLUON AUTOML COMPLETE!\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dfa759b-ed55-4919-9b79-0dd0eb0660e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🔍 INVESTIGATING PERFECT SCORE (F1 = 1.000)\n",
      "================================================================================\n",
      "\n",
      "1️⃣ DATA STATISTICS CHECK:\n",
      "----------------------------------------\n",
      "Train shape: (40000, 6058)\n",
      "Test shape: (10000, 6058)\n",
      "Number of features: 6058\n",
      "Constant features in train: 2\n",
      "Very low variance features: 3560\n",
      "\n",
      "2️⃣ DUPLICATE CHECK:\n",
      "----------------------------------------\n",
      "Duplicate rows in train set: 730\n",
      "Duplicate rows in test set: 52\n",
      "Test samples that appear in train: 379\n",
      "\n",
      "3️⃣ FEATURE IMPORTANCE CHECK:\n",
      "----------------------------------------\n",
      "Top 10 feature importances:\n",
      "  Feature 2: 0.0988\n",
      "  Feature 4: 0.0783\n",
      "  Feature 3: 0.0588\n",
      "  Feature 8: 0.0584\n",
      "  Feature 0: 0.0379\n",
      "  Feature 5967: 0.0326\n",
      "  Feature 5927: 0.0325\n",
      "  Feature 5950: 0.0277\n",
      "  Feature 5919: 0.0245\n",
      "  Feature 5912: 0.0242\n",
      "\n",
      "4️⃣ CLASS SEPARABILITY CHECK:\n",
      "----------------------------------------\n",
      "Logistic Regression CV F1: 1.000 (+/- 0.000)\n",
      "⚠️ Even simple linear model gets perfect score - data is too easy or leaked!\n",
      "\n",
      "5️⃣ SUSPICIOUS FEATURE CHECK:\n",
      "----------------------------------------\n",
      "Maximum correlation with target: 0.7623 (Feature 5)\n",
      "\n",
      "================================================================================\n",
      "💡 RECOMMENDATIONS\n",
      "================================================================================\n",
      "\n",
      "🚨 HIGH RISK OF DATA LEAKAGE DETECTED!\n",
      "\n",
      "Immediate actions:\n",
      "1. Review your preprocessing pipeline:\n",
      "   - Are you using any post-split statistics?\n",
      "   - Is target encoding done correctly?\n",
      "   - Are there any features derived from the target?\n",
      "\n",
      "2. Check original features:\n",
      "   - Is 'Amount' or any ID field acting as proxy for fraud?\n",
      "   - Are there temporal features that shouldn't be there?\n",
      "\n",
      "3. Try training without preprocessing:\n",
      "   ```python\n",
      "   # Train on raw data\n",
      "   from sklearn.ensemble import RandomForestClassifier\n",
      "   rf = RandomForestClassifier()\n",
      "   rf.fit(X_train_original, y_train)  # Use original features\n",
      "   ```\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# DATA LEAKAGE & PERFECT SCORE CHECKER\n",
    "# ===========================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"🔍 INVESTIGATING PERFECT SCORE (F1 = 1.000)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ===========================\n",
    "# 1. CHECK DATA STATISTICS\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n1️⃣ DATA STATISTICS CHECK:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Basic stats\n",
    "print(f\"Train shape: {X_train_ready.shape}\")\n",
    "print(f\"Test shape: {X_test_ready.shape}\")\n",
    "print(f\"Number of features: {X_train_ready.shape[1]}\")\n",
    "\n",
    "# Check for constant features\n",
    "train_df = pd.DataFrame(X_train_ready)\n",
    "test_df = pd.DataFrame(X_test_ready)\n",
    "\n",
    "constant_features = (train_df.nunique() == 1).sum()\n",
    "print(f\"Constant features in train: {constant_features}\")\n",
    "\n",
    "# Check variance\n",
    "low_variance = (train_df.var() < 0.0001).sum()\n",
    "print(f\"Very low variance features: {low_variance}\")\n",
    "\n",
    "# ===========================\n",
    "# 2. CHECK FOR DUPLICATES\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n2️⃣ DUPLICATE CHECK:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Check duplicates within train\n",
    "train_duplicates = train_df.duplicated().sum()\n",
    "print(f\"Duplicate rows in train set: {train_duplicates}\")\n",
    "\n",
    "# Check duplicates within test  \n",
    "test_duplicates = test_df.duplicated().sum()\n",
    "print(f\"Duplicate rows in test set: {test_duplicates}\")\n",
    "\n",
    "# Check if test samples exist in train\n",
    "train_combined = pd.concat([train_df, pd.Series(y_train, name='target')], axis=1)\n",
    "test_combined = pd.concat([test_df, pd.Series(y_test, name='target')], axis=1)\n",
    "\n",
    "# Create hash of each row for comparison\n",
    "train_hash = pd.util.hash_pandas_object(train_df, index=False)\n",
    "test_hash = pd.util.hash_pandas_object(test_df, index=False)\n",
    "\n",
    "overlap = len(set(train_hash) & set(test_hash))\n",
    "print(f\"Test samples that appear in train: {overlap}\")\n",
    "\n",
    "# ===========================\n",
    "# 3. CHECK FEATURE IMPORTANCE\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n3️⃣ FEATURE IMPORTANCE CHECK:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Quick Random Forest to check feature importance\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)\n",
    "rf.fit(X_train_ready, y_train)\n",
    "\n",
    "# Get top features\n",
    "importances = rf.feature_importances_\n",
    "top_features_idx = np.argsort(importances)[-10:][::-1]\n",
    "top_importances = importances[top_features_idx]\n",
    "\n",
    "print(\"Top 10 feature importances:\")\n",
    "for idx, imp in zip(top_features_idx, top_importances):\n",
    "    print(f\"  Feature {idx}: {imp:.4f}\")\n",
    "\n",
    "# Check if any single feature is too dominant\n",
    "max_importance = importances.max()\n",
    "if max_importance > 0.5:\n",
    "    print(f\"\\n⚠️ WARNING: Feature {np.argmax(importances)} has {max_importance:.2%} importance!\")\n",
    "    print(\"This could indicate data leakage!\")\n",
    "\n",
    "# ===========================\n",
    "# 4. CHECK SEPARABILITY\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n4️⃣ CLASS SEPARABILITY CHECK:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Check with simple model\n",
    "lr = LogisticRegression(max_iter=100, random_state=42)\n",
    "lr_scores = cross_val_score(lr, X_train_ready, y_train, cv=3, scoring='f1')\n",
    "print(f\"Logistic Regression CV F1: {lr_scores.mean():.3f} (+/- {lr_scores.std():.3f})\")\n",
    "\n",
    "if lr_scores.mean() > 0.99:\n",
    "    print(\"⚠️ Even simple linear model gets perfect score - data is too easy or leaked!\")\n",
    "\n",
    "# ===========================\n",
    "# 5. CHECK INDIVIDUAL FEATURES\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n5️⃣ SUSPICIOUS FEATURE CHECK:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Check correlation with target\n",
    "correlations = []\n",
    "for i in range(min(X_train_ready.shape[1], 100)):  # Check first 100 features\n",
    "    corr = np.corrcoef(X_train_ready[:, i], y_train)[0, 1]\n",
    "    correlations.append(abs(corr))\n",
    "\n",
    "max_corr = max(correlations)\n",
    "max_corr_idx = np.argmax(correlations)\n",
    "\n",
    "print(f\"Maximum correlation with target: {max_corr:.4f} (Feature {max_corr_idx})\")\n",
    "\n",
    "if max_corr > 0.9:\n",
    "    print(\"⚠️ CRITICAL: Feature has >90% correlation with target - likely data leakage!\")\n",
    "\n",
    "# Check if any feature perfectly separates classes\n",
    "perfect_separator = False\n",
    "for i in range(min(X_train_ready.shape[1], 20)):  # Check first 20 features\n",
    "    feature_vals = X_train_ready[:, i]\n",
    "    \n",
    "    # Check if feature perfectly separates classes\n",
    "    class0_vals = feature_vals[y_train == 0]\n",
    "    class1_vals = feature_vals[y_train == 1]\n",
    "    \n",
    "    if len(class0_vals) > 0 and len(class1_vals) > 0:\n",
    "        if class0_vals.max() < class1_vals.min() or class1_vals.max() < class0_vals.min():\n",
    "            print(f\"⚠️ Feature {i} perfectly separates classes!\")\n",
    "            perfect_separator = True\n",
    "            break\n",
    "\n",
    "# ===========================\n",
    "# 6. RECOMMENDATIONS\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"💡 RECOMMENDATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if max_importance > 0.5 or max_corr > 0.9 or perfect_separator or lr_scores.mean() > 0.99:\n",
    "    print(\"\\n🚨 HIGH RISK OF DATA LEAKAGE DETECTED!\")\n",
    "    print(\"\\nImmediate actions:\")\n",
    "    print(\"1. Review your preprocessing pipeline:\")\n",
    "    print(\"   - Are you using any post-split statistics?\")\n",
    "    print(\"   - Is target encoding done correctly?\")\n",
    "    print(\"   - Are there any features derived from the target?\")\n",
    "    print(\"\\n2. Check original features:\")\n",
    "    print(\"   - Is 'Amount' or any ID field acting as proxy for fraud?\")\n",
    "    print(\"   - Are there temporal features that shouldn't be there?\")\n",
    "    print(\"\\n3. Try training without preprocessing:\")\n",
    "    print(\"   ```python\")\n",
    "    print(\"   # Train on raw data\")\n",
    "    print(\"   from sklearn.ensemble import RandomForestClassifier\")\n",
    "    print(\"   rf = RandomForestClassifier()\")\n",
    "    print(\"   rf.fit(X_train_original, y_train)  # Use original features\")\n",
    "    print(\"   ```\")\n",
    "else:\n",
    "    print(\"\\nNo obvious data leakage detected, but F1=1.0 is still suspicious.\")\n",
    "    print(\"Consider:\")\n",
    "    print(\"• Using a different train/test split\")\n",
    "    print(\"• Checking if the problem is genuinely too easy\")\n",
    "    print(\"• Validating on completely new data\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ec7e8a-0e31-4e40-9c1b-7b0376fcc8df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
